[ZH] [EN]

Lawyer LLaMA
Through fine-tuning via instructions, the LLaMA model has demonstrated very good performance in the general domain. However, due to a lack of appropriate data, few have explored LLaMA's capabilities in the field of law. To fill this gap, we have introduced Lawyer LLaMA, a model that has undergone additional training on legal domain data.

Lawyer LLaMA first underwent continual pretraining on a large-scale legal corpus, enabling it to systematically learn about the legal knowledge system in China. Based on this, we have collected a batch of analyses for the Chinese National Judicial Examination objective questions and answers to legal consultations using ChatGPT, using the collected data to fine-tune the model via instructions, allowing the model to acquire the ability to apply legal knowledge to specific scenarios.

Our model is capable of:

Mastering Chinese Legal Knowledge: It can correctly understand legal concepts in common areas such as civil law, criminal law, administrative law, procedural law, etc. For instance, it has grasped the theory of crime formation in criminal law and can identify the perpetrator, victim, criminal act, subjective mental state, and other components of crime from the factual descriptions of criminal cases. The model, using the legal concepts and theories it has learned, can answer most questions in the legal exam fairly well.

Application in Chinese Legal Practice: It can explain legal concepts in easy-to-understand language and provide basic legal consultation, covering areas such as marriage, lending, maritime, criminal, etc.

In order to contribute to the open research of the Chinese legal large-scale model, this project will open-source a series of legal domain instruction tuning data and parameters of the Chinese legal large-scale model trained based on LLaMA.

We are planning a beta testing experience for Lawyer LLaMA 13B. If you want to try our model, please fill in this questionnaire (in Chinese), and we will contact you by email. (Registration is currently suspended due to limited server resources. We are in the process of model update iterations, please wait for the next round of internal testing.)

News
[2023/10/14] Updated the report Lawyer LLaMA: Enhancing LLMs with Legal Knowledge, providing more technical details and findings.

[2023/6/8] Open-sourced the lawyer-llama-13b-beta1.0 model parameters.

[2023/5/25] Open-sourced larger-scale instruction fine-tuning data, released dialogue data related to legal articles and user questions.

[2023/5/25] Published Lawyer LLaMA Technical Report.

[2023/4/13] Open-sourced instruction fine-tuning data generated by ChatGPT, including 2k legal exam question answers and 5k legal consultation replies.

Update Plans
 Open-source larger-scale instruction tuning data
 Open-source legal consultation multi-turn dialogue data (continually increasing)
 Open-source consulting model for specific legal fields
 Open-source pretraining model for the general legal domain
Training Data
Legal-domain corpus
We collected some public legal data for the continual training of the model, including legal provisions, judgment documents, etc.

General instruction tunining data
Alpaca-GPT4 52k in Chinese，52k in English。

Legal instruction tuning data
Overview of open-source data
File	Size	Description
judical_examination.json	2,000	Answers to law exam questions generated by ChatGPT
judical_examination_v2.json	5,000	Answers to law exam questions generated by ChatGPT (the second batch)
legal_advice.json	5,000	Legal counsel responses generated by ChatGPT
legal_counsel_v2.json	8,000	Legal counsel responses generated by ChatGPT (the second batch)
legal_counsel_with_article_v2.json	1,000	Legal counsel responses generated by ChatGPT based on legal articles
legal_counsel_multi_turn_with_article_v2.json	476	ChatGPT generates multi-turn legal consultation dialogues based on legal articles
National Judicial Examination
We input the test questions in the JEC-QA Chinsese National Judicial Examination into ChatGPT and let it generate an analysis of each answer.

Human:

根据《物权法》，下列关于物权变动的特别规定，表述正确吗？
因继承或者受遗赠取得物权的，自继承或者受遗赠开始时发生效力
请给出详细的推理过程之后再给出答案。

Assistant:

这个表述是正确的。
根据《物权法》第X条规定：“因继承或者受遗赠取得物权的，自继承或者受遗赠开始时发生效力。”这意味着，当一个人通过继承或受遗赠获得物权时，这个物权的效力是从继承或受遗赠开始时就生效的，而不是从物权转移的时间开始生效。这是因为，继承或受遗赠是一种法定的方式来获得物权，因此，物权的效力应该从这个法定的时间点开始生效。
Legal Consultation
We collected some consulting questions from a open-source dataset, input ChatGPT, let ChatGPT act as a lawyer to answer questions .

Human:

是这么个回事，关于我儿子今年2月27日背着我们大人买了一台轻便女式摩托车麻烦你帮忙看怎么解决？

Assistant:

首先，根据法律规定，未满18岁的未成年人是无法独立签订合同的，因此你的儿子在未经你的同意的情况下购买摩托车是无效的。
其次，根据《中华人民共和国道路交通安全法》的规定，未满18周岁的人不得驾驶摩托车，因此你的儿子也无权驾驶这辆摩托车。
建议你尽快联系卖家，说明情况并要求退货。如果卖家不同意，你可以向消费者协会或相关部门投诉，寻求法律帮助。同时，你也需要对你的儿子进行教育，让他了解道路交通安全法规，避免再次发生类似的情况。
We try to input relevant laws and regulations together, which can improve the quality of ChatGPT generation.

Related Legal Articles:

《民法典》第一千零八十七条：离婚时，夫妻的共同财产由双方协议处理；协议不成的，由人民法院根据财产的具体情况，按照照顾子女、女方和无过错方权益的原则判决。对夫或者妻在家庭土地承包经营中享有的权益等，应当依法予以保护。
《民法典》第一千零六十三条：下列财产为夫妻一方的个人财产：（一）一方的婚前财产；（二）一方因受到人身损害获得的赔偿或者补偿；（三）遗嘱或者赠与合同中确定只归一方的财产；（四）一方专用的生活用品；（五）其他应当归一方的财产。
《民法典》第一千零六十二条：夫妻在婚姻关系存续期间所得的下列财产，为夫妻的共同财产，归夫妻共同所有：（一）工资、奖金、劳务报酬；（二）生产、经营、投资的收益；（三）知识产权的收益；（四）继承或者受赠的财产，但是本法第一千零六十三条第三项规定的除外；（五）其他应当归共同所有的财产。夫妻对共同财产，有平等的处理权。

Human:

你好，离婚后夫妻的财产是怎么分配的

Assistant:

您好，根据《民法典》的相关规定，离婚后夫妻的财产分配可以通过夫妻双方协商处理，如果没有协商一致，则需要由法院根据财产的具体情况，按照照顾子女、女方和无过错方权益的原则进行判决。对于夫妻在婚姻关系存续期间所得的共同财产，包括工资、奖金、劳务报酬、生产、经营、投资的收益、知识产权的收益、继承或者受赠的财产以及其他应当归共同所有的财产，应当平分。而夫妻在婚姻关系存续期间所获得的个人财产，包括婚前财产、因受到人身损害获得的赔偿或者补偿、遗嘱或者赠与合同中确定只归一方的财产、一方专用的生活用品，应当归该方所有。请问你们在婚姻关系存续期间所得的财产情况如何呢？
Model Parameters
The following versions of Lawyer LLaMA are currently publicly available:

lawyer-llama-13b-beta1.0: Based on Chinese-LLaMA-13B, without legal corpus continual training, using general instruction and legal instruction for SFT, equipped with a marriage-related legal articel retrieval module.
For the download address and usage method, see demo/run_inference.md.

Case Study
We selected LLaMA 13B as the base model, used the legal domain corpus for further pre-training, and fine-tuned in the general domain and legal domain instructions.

The following compares the model and ChatGPT's responses to some input samples:

Understanding of legal concepts
Legal Consultation
Acknowledgement
Our project have received help from the following projects, and we would like to express our gratitude.

https://jecqa.thunlp.org/

https://opendata.pku.edu.cn/dataset.xhtml?persistentId=doi:10.18170/DVN/OLO4G8

https://github.com/tatsu-lab/stanford_alpaca

https://github.com/LianjiaTech/BELLE

https://github.com/ymcui/Chinese-LLaMA-Alpaca

https://github.com/pointnetwork/point-alpaca

Constributors of Lawyer LLaMA：

Quzhe Huang*, Mingxu Tao*, Zhenwei An*, Chen Zhang*, Cong Jiang, Zhibin Chen, Zirui Wu, Yansong Feng

* Equal Contribution

This project is carried out under the guidance of Prof. Yansong Feng.

Limitations and Usage Restrictions
The content of this project is only for academic research and should not be used for commercial purposes or any other uses that could harm society. When using parts involving third-party code, please strictly follow the corresponding open-source agreements.

The data used in this project is generated by ChatGPT, has not been rigorously validated, and may contain errors. Please be cautious and discerning when using it.

The model outputs in this project are not professional legal consultation results and may contain errors. If you need legal assistance, please seek help from professionals.

Citation
If you use the contents of this project, or believe that this project has been helpful for your research, please cite this project.

@article{lawyer-llama-report,
  title={Lawyer LLaMA Technical Report},
  author={Quzhe Huang and Mingxu Tao and Zhenwei An and Chen Zhang and Cong Jiang and Zhibin Chen and Zirui Wu and Yansong Feng},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.15062}
}

@misc{Lawyer-LLama,
  author={Quzhe Huang and Mingxu Tao and Zhenwei An and Chen Zhang and Cong Jiang and Zhibin Chen and Zirui Wu and Yansong Feng},
  title={Lawyer Llama},
  year={2023},
  publisher={GitHub},
  journal={GitHub repository},
  howpublished={\url{https://github.com/AndrewZhe/lawyer-llama}},
}
